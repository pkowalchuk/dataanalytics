from welly import Well
from welly import Curve


well=Well.from_las('Data/LAS/8267_a0801_1996_comp.las')
well


tracks =['MD','GR', ['NPHI','RHOB','DRHO'],'DT']
well.plot(tracks=tracks)


well.data['GR']


gr=well.data['GR']
gr.describe()


gr=well.data['GR']
gr[2600:3000].describe()


import welly.quality as quality

test = {'Each':[quality.no_flat,
                quality.no_gaps,
                quality.not_empty
        ],
       'GR':[quality.all_above(25)
        ]}

from IPython.display import HTML
data_qc_table=well.qc_table_html(test)
HTML(data_qc_table)


test = {'Each':[quality.no_flat,
                quality.no_gaps,
                quality.not_empty,
                quality.fraction_not_nans
        ],
       'GR':[quality.all_above(25)
        ]}

data_qc_table=well.qc_table_html(test)
HTML(data_qc_table)


test = {'Each':[quality.no_flat,
                quality.no_gaps,
                quality.not_empty,
                quality.fraction_not_nans,
                quality.no_spikes(100),
                quality.count_spikes
        ],
       'GR':[quality.all_above(25)
        ]}

data_qc_table=well.qc_table_html(test)
HTML(data_qc_table)


gamma_dataframe=gr.df
gamma_dataframe


well_dataframe=well.df()
well_dataframe


len(gamma_dataframe)


len(well_dataframe)


class Curve:
    def __init__(self, well_name, well_location, curve_name, data):
        self.well_name = well_name
        self.well_location = well_location
        self.curve_name = curve_name
        self.data = data

    def get_well_name(self):
        return self.well_name

    def get_well_location(self):
        return self.well_location

    def get_curve_name(self):
        return self.curve_name

    def get_data(self, start=None, end=None):
        if start is None and end is None:
            return self.data
        elif start is None:
            return self.data[self.data.index <= end]
        elif end is None:
            return self.data[self.data.index >= start]
        else:
            return self.data[(self.data.index >= start) & (self.data.index <= end)]


curve=Curve("well 1","cerro dragon","gamma ray",gamma_dataframe)


print("Well name: "+curve.well_name+"\nLocation: "+curve.well_location+"\nCurve name: "+curve.curve_name+"\nData:\n"+str(curve.data))


print("Well name: "+curve.get_well_name()+"\nLocation: "+curve.get_well_location()+"\nCurve name: "+curve.get_curve_name()+"\nData:\n"+str(curve.get_data()))


print("Well name: "+curve.get_well_name()+"\nLocation: "+curve.get_well_location()+"\nCurve name: "+curve.get_curve_name()+"\nData:\n"+str(curve.get_data(30,3000)))


print("Well name: "+curve.well_name+"\nLocation: "+curve.well_location+"\nCurve name: "+curve.curve_name+"\nData:\n"+str(curve.data[30:3000]))


import lasio

las_file_path = 'Data/LAS/8267_a0801_1996_comp.las'

well = lasio.read(las_file_path)

df=well.df()
df[30:3000]


import pandas as pd

file_path = 'Data//ASCII//Swell-1A_AsciiDrillData_183.0-5006.csv'
df = pd.read_csv(file_path)
df.head()


columns=df.columns
file_path = 'Data//ASCII//Swell-1A_AsciiDrillData_183.0-5006.csv'
df = pd.read_csv(file_path, skiprows=1)
df.head()


df.columns=columns
df.head()


df.plot(subplots=True, figsize=(15,35))


import numpy as np

df.replace(-999.25, np.nan, inplace=True)
df.head()


print("Number of missing readings")
for column in df.columns:
    count_nan = df[column].isna().sum()
    print(f"{column}: {count_nan}")


import pandas as pd
import numpy as np

# Function to replace one NaN with the average of the surrounding values
def replace_one_nan_with_avg(df, column_name):
    for i in range(1, len(df[column_name]) - 1):
        if pd.isna(df.at[i, column_name]):
            if not pd.isna(df.at[i - 1, column_name]) and not pd.isna(df.at[i + 1, column_name]):
                df.at[i, column_name] = (df.at[i - 1, column_name] + df.at[i + 1, column_name]) / 2
            else:
                df.at[i, column_name] = np.nan
    return df

# Store the initial NaN count for each column in a dictionary
initial_nan_dic = df.isna().sum().to_dict()

# Replace NaNs in specified columns
for column in columns:  # 'columns' should be defined elsewhere with the list of columns
    replace_one_nan_with_avg(df, column)

# Display the original and new NaN counts
for column in df.columns:
    count_nan = df[column].isna().sum()
    print(f"Column: {column}: new NaN {count_nan}, old NaN {initial_nan_dic[column]}")



def replace_many_nan_with_avg(df, column_name):
    for i in range(len(df[column_name])):
        if pd.isna(df[column_name][i]):
            prev_value = None
            next_value = None
            for j in range(i-1, -1, -1):
                if not pd.isna(df[column_name][j]):
                    prev_value = df[column_name][j]
                    break
            for j in range(i+1, len(df[column_name])):
                if not pd.isna(df[column_name][j]):
                    next_value = df[column_name][j]
                    break
            if prev_value is None and next_value is None:
                df[column_name][i] = np.nan
            elif prev_value is None:
                df[column_name][i] = next_value
            elif next_value is None:
                df[column_name][i] = prev_value
            else:
                df[column_name][i] = (prev_value + next_value) / 2
    return df

for column in columns:
    replace_many_nan_with_avg(df,column)

for column in df.columns:
    count_nan = df[column].isna().sum()
    print(f"Column: {column}: new NaN {count_nan}, old NaN {initial_nan_dic[column]}")


df.head()

df.plot(subplots=True, figsize=(15,35))


import pandas as pd
import numpy as np

# Function to replace many NaNs with the average of the surrounding values
def replace_many_nan_with_avg(df, column_name):
    for i in range(len(df[column_name])):
        if pd.isna(df.at[i, column_name]):  # Use df.at for getting values
            prev_value = None
            next_value = None

            # Find the previous non-NaN value
            for j in range(i - 1, -1, -1):
                if not pd.isna(df.at[j, column_name]):  # Use df.at for getting values
                    prev_value = df.at[j, column_name]
                    break

            # Find the next non-NaN value
            for j in range(i + 1, len(df[column_name])):
                if not pd.isna(df.at[j, column_name]):  # Use df.at for getting values
                    next_value = df.at[j, column_name]
                    break

            # Replace NaN based on available values
            if prev_value is None and next_value is None:
                df.at[i, column_name] = np.nan  # No surrounding values
            elif prev_value is None:
                df.at[i, column_name] = next_value  # Only next value is available
            elif next_value is None:
                df.at[i, column_name] = prev_value  # Only previous value is available
            else:
                df.at[i, column_name] = (prev_value + next_value) / 2  # Average of both
    return df

# Store the initial NaN count for each column
initial_nan_dic = df.isna().sum().to_dict()

# Apply the NaN replacement function to the specified columns
for column in columns:  # 'columns' should contain the list of relevant columns
    replace_many_nan_with_avg(df, column)

# Display the new and old NaN counts for comparison
for column in df.columns:
    count_nan = df[column].isna().sum()
    print(f"Column: {column}: new NaN {count_nan}, old NaN {initial_nan_dic[column]}")

# Display the head of the DataFrame
df.head()

# Plot the data in the DataFrame
df.plot(subplots=True, figsize=(15, 35))


import pandas as pd

# create a sample dataframe
dft = pd.DataFrame({'values': [4.72, 3.89, 3.75, 4.96, 3.62, 4.68, 4.34, 3.63, 3.54, 6.71, 7.89, 3.58, 3.71, 4.19, 3.4, 3.01, 3.33, 4.36, 3.63, 3.61, 3.23, 4.7, 
                              4.57, 2.84, 2.63, 2.86, 2.86, 2.66, 3.04, 3.06, 2.67, 2.57, 2.9, 2.55, 3.33, 2.58, 2.7, 2.38, 2.71, 2.25, 2.05, 3, 3.12, 2.36, 2.76, 
                              3.52, 3.11, 2.94, 2.73, 2.57, 3.35, 3.07, 2.69, 2.95, 3.14, 3.8, 3.26, 2.91, 3.16, 3.23, 3.07, 3.32, 3.56, 3.35, 3.35, 5.31,7.21, 
                              5.14, 4.11, 8.71, 6.28, 6.27, 4.13, 3.11, 4.46, 3.47, 3.33, 2.9, 3.3, 3.28, 3.3, 3.28]})

# define the window size
WS = 5

# calculate the rolling average
dft['rolling_average'] = dft['values'].rolling(window=WS).mean()

dft.plot()


# define the window size
WS = 20

dfs=pd.DataFrame()
for column in columns:
    dfs[column] = df[column].rolling(window=WS).mean()

dfs.plot(subplots=True, figsize=(15,35))


def read_las_files(file_list):
    dfs=pd.DataFrame()
    for file in file_list:
        well = lasio.read('Data/LAS/'+file)
        df = well.df()
        dfs=pd.concat([dfs, df], ignore_index=True)
    return dfs


file_list=['210915_IOA_07_BDC-2-04_TD_695.las','210916_IOA_08_BDC-2-04_TD_695.las','210917_IOA_09_BDC-2-04_TD_1171.las','210918_IOA_10_BDC-2-04_TD_1551.las',
        '210919_IOA_11_BDC-2-04_TD_2047.las','210920_IOA_12_BDC-2-04_TD_2261.las']
df=read_las_files(file_list)


print("Column Names:")
print(df.columns)


import matplotlib.pyplot as plt 

ax=df.plot(y='HDEP',use_index=True)
ax.invert_yaxis()
plt.show()


df['HDEP'].is_monotonic_increasing


ax = df.loc['00:00:00.22-09-21':, 'HDEP'].plot()
ax.invert_yaxis()
plt.xticks(rotation=45)
plt.show()


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Sample DataFrame with 'HDEP' values (Hole Depth)
data = {
    'Index': range(1, 11),
    'HDEP': [1000, 1050, 1100, 1080, 1150, 1200, 1190, 1250, 1300, 1280]
}

# Create the DataFrame
df = pd.DataFrame(data)
df.set_index('Index', inplace=True)

# Display the original DataFrame
print("Original DataFrame:")
print(df)

# Identify non-monotonic increasing points
# A point is non-monotonic if it is less than or equal to the previous point
non_monotonic_mask = df['HDEP'] <= df['HDEP'].shift(1)

# Display the mask
print("\nNon-Monotonic Mask:")
print(non_monotonic_mask)

# Plotting 'HDEP'
ax = df.plot(y='HDEP', use_index=True, label='HDEP', figsize=(10, 6), marker='o')

# Highlight the non-monotonic points
ax.plot(df.index[non_monotonic_mask], df['HDEP'][non_monotonic_mask], 'ro', label='Non-Monotonic Points')

# Invert the y-axis to represent depth correctly
ax.invert_yaxis()

# Add labels and title
ax.set_ylabel('HDEP (m)')
ax.set_xlabel('Run Index')
ax.set_title('HDEP Plot with Non-Monotonic Points Highlighted')

# Show legend
ax.legend()

# Display the plot
plt.show()



df['RPMTOTAL'].plot(kind='kde')


df_new = df.loc[df['RPMTOTAL'] > 0]
df_new['RPMTOTAL'].plot(kind='kde')


from sklearn.neighbors import KernelDensity

# Extract the RPMTOTAL column
rpmtotal = df_new['RPMTOTAL'].values.reshape(-1, 1)

# Fit the kernel density estimator
kde = KernelDensity(kernel='gaussian', bandwidth=8).fit(rpmtotal)

# Create a range of values to evaluate the estimator
x = np.linspace(rpmtotal.min(), rpmtotal.max(), 1000).reshape(-1, 1)

# Evaluate the estimator at the given values
y = np.exp(kde.score_samples(x))

# Plot the KDE distribution
plt.plot(x, y)
plt.xlabel('RPMTOTAL')
plt.ylabel('Density')
plt.title('KDE Distribution of RPMTOTAL')
plt.show()


from sklearn.cluster import KMeans

# Fit the KMeans estimator
kmeans = KMeans(n_clusters=5,n_init=10).fit(rpmtotal)

# Get the cluster labels
labels = kmeans.labels_

# Get the indices of the clusters
cluster_indices = [np.where(labels == i)[0] for i in range(kmeans.n_clusters)]

# Segregate the clusters into smaller arrays
clusters = [rpmtotal[indices] for indices in cluster_indices]

# Plot the normal distributions for each array
for i, cluster in enumerate(clusters):
    mu, std = cluster.mean(), cluster.std()
    x = np.linspace(mu - 3 * std, mu + 3 * std, 1000)
    y = np.exp(-0.5 * ((x - mu) / std) ** 2) / (std * np.sqrt(2 * np.pi))
    plt.plot(x, y, label=f'Cluster {i+1}')
plt.xlabel('RPMTOTAL')
plt.ylabel('Density')
plt.title('Normal Distributions of RPMTOTAL Clusters')
plt.legend()
plt.show()



from scipy import stats

def plot_normal_distribution(mean, std, ci):
    x_axis = np.arange(0, 260, 0.001)
    pdf = stats.norm.pdf(x_axis, mean, std)

    fig, ax = plt.subplots()
    fig.set_figwidth(15) # Set the width of the figure to 10 inches
    ax.plot(x_axis, pdf)

    std_lim = stats.norm.ppf(1 - (1 - ci) / 2) # 95% CI
    low = mean - std_lim * std
    high = mean + std_lim * std

    ax.fill_between(x_axis, pdf, where=(low < x_axis) & (x_axis < high))
    ax.text(low, 0, f'{low:.2f}', ha='center',rotation=45)
    ax.text(high, 0, f'{high:.2f}', ha='center',rotation=45)

    plt.show()
    
plot_normal_distribution(150, 40, 0.90)


for i, cluster in enumerate(clusters):
    mu, std = cluster.mean(), cluster.std()
    print(f'Cluster {i+1}: Mean = {mu:.2f}, Standard Deviation = {std:.2f}')


for i, cluster in enumerate(clusters):
    plot_normal_distribution(cluster.mean(), cluster.std(), 0.95)


def plot_normal_distribution(mean, std, ci, color):
    x_axis = np.arange(0, 260, 0.001)
    pdf = stats.norm.pdf(x_axis, mean, std)

    ax.plot(x_axis, pdf, color=color)

    std_lim = stats.norm.ppf(1 - (1 - ci) / 2) # 95% CI
    low = mean - std_lim * std
    high = mean + std_lim * std

    ax.fill_between(x_axis, pdf, where=(low < x_axis) & (x_axis < high))
    ax.text(low, 0.015, f'{low:.2f}', ha='left', fontweight='bold', rotation=45)
    ax.text(high, 0.015, f'{high:.2f}', ha='center', fontweight='bold', rotation=45)

fig, ax = plt.subplots(figsize=(25, 5))

colors = ['red', 'green', 'blue', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']

for i, cluster in enumerate(clusters):
    plot_normal_distribution(cluster.mean(), cluster.std(), 0.95, colors[i % len(colors)])

plt.show()



